import streamlit as st
from PIL import Image
import tensorflow as tf
import numpy as np

# ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = tf.keras.models.load_model("pet_ex.keras")

# CSS ìŠ¤íƒ€ì¼ë¡œ ë°°ê²½ ì´ë¯¸ì§€ ì„¤ì • (JPG íŒŒì¼ ì‚¬ìš©)
page_bg_img = '''   
<style>
body {
    background-image: url("https://img.freepik.com/free-vector/cute-animal-pattern-background-wallpaper-paw-print-vector-illustration_53876-146422.jpg");
    background-size: cover;
    background-repeat: repeat;
    background-attachment: fixed;
}
</style>
'''

# HTMLì„ ì´ìš©í•´ ë°°ê²½ ì´ë¯¸ì§€ ì‚½ì…
st.markdown(page_bg_img, unsafe_allow_html=True)

# ê³¼ê±°ì— í…ŒìŠ¤íŠ¸í•œ ì‚¬ì§„ê³¼ ê²°ê³¼ ì €ì¥ (ì„¸ì…˜ ìƒíƒœ í™œìš©)
if 'past_results' not in st.session_state:
    st.session_state['past_results'] = []

# ì‚¬ìš©ìê°€ ì„ íƒí•œ ì‹¤ì œ ê°ì • ì €ì¥
if 'user_selections' not in st.session_state:
    st.session_state['user_selections'] = []

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ ë° RGBA -> RGB ë³€í™˜)
def preprocess_image(image):
    if image.mode != 'RGB':
        image = image.convert('RGB')  # RGBA ë“± ë‹¤ë¥¸ ëª¨ë“œë¥¼ RGBë¡œ ë³€í™˜
    image = image.resize((224, 224))  # ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
    image = np.array(image) / 255.0  # ì •ê·œí™”
    image = np.expand_dims(image, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    return image

# ì˜ˆì¸¡ í•¨ìˆ˜ (ëª¨ë“  í´ë˜ìŠ¤ ë¹„ìœ¨ ë°˜í™˜)
def predict_emotion(image):
    predictions = model.predict(image)[0]  # ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼
    emotions = ['Angry', 'Happy', 'Sad', 'Other']  # í´ë˜ìŠ¤ ì´ë¦„
    emotion_confidences = {emotions[i]: predictions[i] * 100 for i in range(len(emotions))}  # ê° ê°ì •ì˜ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°
    predicted_emotion = max(emotion_confidences, key=emotion_confidences.get)  # í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ê°ì •
    return emotion_confidences, predicted_emotion

# ì›¹ í˜ì´ì§€ ì œëª© (ê°•ì•„ì§€ ë°œë°”ë‹¥ ì´ëª¨í‹°ì½˜ ì¶”ê°€)
st.title("ğŸ¾ Pet Emotion Classifier ğŸ¾")

# íŒŒì¼ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤
uploaded_file = st.file_uploader("ì• ì™„ë™ë¬¼ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ ì²˜ë¦¬
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded Image', use_column_width=True)

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
    preprocessed_image = preprocess_image(image)
    emotion_confidences, predicted_emotion = predict_emotion(preprocessed_image)

    # ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
    st.write("ì˜ˆì¸¡ ê²°ê³¼:")
    for emotion, confidence in emotion_confidences.items():
        st.write(f"**{emotion}**: {confidence:.2f}%")
    
    st.write(f"ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ê°ì •: **{predicted_emotion}**")

    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
    st.session_state['past_results'].append({
        'image': image,
        'predicted_emotion': predicted_emotion,
        'confidence': emotion_confidences[predicted_emotion]
    })

    # ì‚¬ìš©ìê°€ ì‹¤ì œ ê°ì •ì„ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë¼ë””ì˜¤ ë²„íŠ¼ ì¶”ê°€
    st.write("ì´ ì‚¬ì§„ì˜ ì‹¤ì œ ê°ì •ì„ ì„ íƒí•˜ì„¸ìš”:")
    user_emotion = st.radio("ì‹¤ì œ ê°ì • ì„ íƒ:", ('Happy', 'Sad', 'Angry', 'Other'))

    if st.button("ì„ íƒ ì™„ë£Œ"):
        # ì‚¬ìš©ìì˜ ì„ íƒì„ ì €ì¥
        st.session_state['user_selections'].append({
            'image_name': uploaded_file.name,
            'user_emotion': user_emotion
        })
        st.write(f"ì„ íƒí•˜ì‹  ê°ì •: {user_emotion}")

# ì‚¬ì´ë“œë°”ì— í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
st.sidebar.title("í…ŒìŠ¤íŠ¸í•œ ì´ë¯¸ì§€ë“¤")
st.sidebar.write("ì—¬íƒœê¹Œì§€ í…ŒìŠ¤íŠ¸í•œ ì‚¬ì§„ë“¤ì…ë‹ˆë‹¤.")
for result in st.session_state['past_results']:
    st.sidebar.image(result['image'], caption=f"{result['confidence']:.2f}%ë¡œ {result['predicted_emotion']}", use_column_width=True)

# ì‚¬ìš©ìê°€ ì„ íƒí•œ ê°ì • ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
st.sidebar.write("ì‚¬ìš©ìê°€ ì„ íƒí•œ ê°ì •:")
for selection in st.session_state['user_selections']:
    st.sidebar.write(f"{selection['image_name']}: {selection['user_emotion']}")
